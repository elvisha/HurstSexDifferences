{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sex Classification Using HE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in modules and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in subj_num and test_holdout indices\n",
    "num = pd.read_csv('subj_num.txt', header=None)\n",
    "num = num.values\n",
    "test = pd.read_csv('test_holdout.csv', header=None)\n",
    "test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in HE and sex data\n",
    "#data contains HE for all subjects x ROIs based on the atlas being used\n",
    "data = pd.read_csv('he_fs86.csv', header=0)\n",
    "data = data.values\n",
    "#sex is binary variable - males are '1', females are '0'\n",
    "sex = pd.read_csv('subj_sex.csv', header=None)\n",
    "sex = sex.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing sets using pre-determined indices (generated in HCP_HE_sexclf_traintestsplit notebook)\n",
    "#this was done this way to make sure all atlases have the exact same train-test split \n",
    "\n",
    "#get indices for training and testing subsets\n",
    "train_idx=np.isin(num,test,invert=True)\n",
    "test_idx=np.isin(num,test)\n",
    "\n",
    "#partition data and sex labels into training and testing subsets\n",
    "x_train=data[train_idx.ravel(),:]\n",
    "x_test=data[test_idx.ravel(),:]\n",
    "y_train=sex[train_idx.ravel(),:]\n",
    "y_test=sex[test_idx.ravel(),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Using Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set all the hyperparameters you want to tune using nested CV\n",
    "#param_grid = {'clf__kernel': ['linear','rbf'], 'clf__C': [1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5], 'clf__gamma': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]}\n",
    "param_grid = {'clf__kernel': ['linear'], 'clf__C': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1]}\n",
    "\n",
    "#choose specific metrics that you want to look at during CV\n",
    "scores = ['roc_auc']\n",
    "#scores = ['accuracy', 'roc_auc', 'precision','recall','balanced_accuracy']\n",
    "\n",
    "\n",
    "#set number of iterations through nested CV loop\n",
    "iterations=100\n",
    "\n",
    "#set up pipeline for analysis so that data transformation takes place within each CV fold\n",
    "cv_steps = [('scaler', StandardScaler()), ('clf', SVC(max_iter=100000))]\n",
    "cv_pipeline = Pipeline(cv_steps)\n",
    "\n",
    "#create array to store nested CV scores\n",
    "nested_scores = np.zeros(iterations)\n",
    "\n",
    "best_params = ['']*iterations\n",
    "\n",
    "#set up nested CV pipeline\n",
    "for i in range(iterations):\n",
    "    \n",
    "    print(\"Nested CV - Loop %d\" % (i+1))\n",
    "    \n",
    "    #set parameters for inner and outer loops for CV\n",
    "    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    \n",
    "    \n",
    "    for scoring in scores:\n",
    "        #print specific hyperparameter being tuned\n",
    "        #print(\"Tuning hyperparameters for %s\" % score)\n",
    "\n",
    "        #define classifier with pipeline and grid-search CV for inner loop\n",
    "        clf = GridSearchCV(cv_pipeline, param_grid=param_grid, cv=inner_cv, \n",
    "                           scoring='%s' % scoring, n_jobs=-1, iid=False, refit=True, verbose=0)\n",
    "\n",
    "        #fit classifier\n",
    "        clf.fit(x_train, y_train.ravel())\n",
    "\n",
    "        #save parameters corresponding to the best score\n",
    "        best_params[i] = clf.best_params_\n",
    "        #print(\"Best Parameters = %s\" % clf.best_params_)\n",
    "        #print()\n",
    "        \n",
    "        #print detailed classification report\n",
    "        #print(\"Detailed classification report:\")\n",
    "        #print(\"The model is trained on the full development set.\")\n",
    "        #print(\"The scores are computed on the full validation set.\")\n",
    "        #print()\n",
    "        #y_true, y_pred = y_val, clf.predict(x_val)\n",
    "        #print(classification_report(y_true, y_pred))\n",
    "        \n",
    "        #call cross_val_score for outer loop\n",
    "        nested_score = cross_val_score(clf, X=x_train, y=y_train.ravel(), cv=outer_cv, \n",
    "                                       scoring='%s' % scoring, verbose=0)\n",
    "        nested_scores[i] = nested_score.mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify best score based on nested CV \n",
    "best_score=np.amax(nested_scores)\n",
    "#print(max_score)\n",
    "#identify specific parameters associated with best score\n",
    "idx=np.where(nested_scores == best_score)\n",
    "best_params[np.asarray(idx)[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model with Optimized Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize all training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_t = scaler.transform(x_train)\n",
    "x_test_t = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate SVC model based on optimized parameters \n",
    "#can use mean hyperparamaters of n best models where n is iterations in hyperparameter search\n",
    "#or can use hyperparameter of best models out of n best models \n",
    "model = SVC(C=0.1, kernel='linear');\n",
    "model.fit(x_train_t, y_train.ravel());\n",
    "print(\"Score = %1.4f\" %(model.score(x_test_t,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#transform binary labels to 'Female' and 'Male'\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([\"F\", \"M\"])\n",
    "y_train_label=le.inverse_transform(y_train.ravel())\n",
    "y_test_label=le.inverse_transform(y_test.ravel())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "fig.suptitle('FS86 - SVM Linear Kernel with C=0.1', fontsize=12)\n",
    "ax.set_xlabel('xlabel', fontsize=12)\n",
    "ax.set_ylabel('ylabel', fontsize=12)\n",
    "\n",
    "cm = ConfusionMatrix(model, classes=['M','F'], cmap='Blues', fontsize=12, ax=ax, title=' ')\n",
    "\n",
    "\n",
    "#fit the model\n",
    "cm.fit(x_train_t, y_train_label)\n",
    "\n",
    "#creates confusion matrix\n",
    "cm.score(x_test_t, y_test_label)\n",
    "\n",
    "#plot confusion matrix\n",
    "cm.poof()\n",
    "\n",
    "#save confusion matrix image\n",
    "fig.savefig('cm_fs86.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ROC curve for classifier\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#set classes\n",
    "classes=['female', 'male']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "ax.set_frame_on(False)\n",
    "fig.suptitle('FS86 - SVM Linear Kernel with C=0.1', fontsize=12)\n",
    "ax.set_xlabel('xlabel', fontsize=12)\n",
    "ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "ax.set_ylabel('ylabel', fontsize=12)\n",
    "\n",
    "#ax.grid(False)\n",
    "\n",
    "visualizer = ROCAUC(model, classes=['M','F'], macro=False, micro=False, per_class=False, \n",
    "                    fontsize=16, ax=ax, title=' ')\n",
    "\n",
    "#Fit the training data to the visualizer\n",
    "visualizer.fit(x_train_t, y_train.ravel())\n",
    "\n",
    "#Evaluate the model on the test data\n",
    "visualizer.score(x_test_t, y_test.ravel()) \n",
    "\n",
    "#Draw/show/poof the data\n",
    "visualizer.poof()\n",
    "\n",
    "#save confusion matrix\n",
    "fig.savefig('roc_fs86.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import labels file pertaining to atlas being used for training/testing\n",
    "labels = pd.read_csv('fs86_labels.csv', header=0)\n",
    "\n",
    "#define feature importances graph\n",
    "def f_importances(coef, names, top=-1):\n",
    "    imp = coef\n",
    "    imp, names = zip(*sorted(list(zip(imp, names))))\n",
    "\n",
    "    # Show all features\n",
    "    if top == -1:\n",
    "        top = len(names)\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.barh(range(top), imp[::-1][0:top], align='center')\n",
    "    plt.yticks(range(top), names[::-1][0:top])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Specify the top n features you want to visualize.\n",
    "# can use np.square, abs, or neither if you want to see positive and negative coefficients\n",
    "f_importances(np.square(model.coef_[0]), labels, top=10)\n",
    "\n",
    "#write model feature importances to csv file\n",
    "import csv\n",
    "with open('featimp_tt.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(model.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
