{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in input (volume or HE) and sex data\n",
    "#input data contains volume or HE for all subjects x ROIs based on the atlas being used\n",
    "data = pd.read_csv('input_data.csv', header=0)\n",
    "data = data.values\n",
    "#sex is binary variable - males are '1', females are '0'\n",
    "sex = pd.read_csv('sex.txt', header=None)\n",
    "sex = sex.values\n",
    "#read in subj_num  indices\n",
    "num = pd.read_csv('num.txt', header=None)\n",
    "num = num.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create logical variable to identify males and females\n",
    "male = sex==1\n",
    "female = sex==0\n",
    "\n",
    "#save male and female he data into separate arrays\n",
    "#idx_male = num[male.ravel(),:]\n",
    "#idx_female = num[female.ravel(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load indices for all test holdout sets - to keep it consistent across all atlases\n",
    "test_indices = pd.read_csv('test_indices.txt', header=None)\n",
    "test_indices = test_indices.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set the number of random permutations you want to do, should be the same value as 'iterations' in he_sexclf_traintestsplit\n",
    "permutations = perm\n",
    "\n",
    "#size of test_set for each permutation\n",
    "test_num=test_indices.shape[1]\n",
    "\n",
    "#create variable to save optimised_c from each of the iterations \n",
    "optimised_c = np.zeros(permutations)\n",
    "accuracy = np.zeros(permutations)\n",
    "auc = np.zeros(permutations)\n",
    "predictions = np.zeros([permutations,test_num])\n",
    "feat_imp = np.zeros([permutations,data.shape[1]])\n",
    "\n",
    "\n",
    "for idx in range(permutations):\n",
    "    \n",
    "    print(\"Permutation %d\" % (idx + 1))\n",
    "    print(time.localtime(time.time()))\n",
    "    \n",
    "    #randomly generate subset of n males and n females\n",
    "    #n=num_random\n",
    "    #idx_male_n = idx_male[np.random.choice(idx_male.shape[0], n, replace=False), :]\n",
    "    #idx_female_n = idx_female[np.random.choice(idx_female.shape[0], n, replace=False), :]\n",
    "    \n",
    "    #create logical vector to identify males and females chosen by random permutation\n",
    "    #male_idx = np.isin(num,idx_male_n)\n",
    "    #female_idx = np.isin(num,idx_female_n)\n",
    "    \n",
    "    #generate arrays of HE or volume data for males and females\n",
    "    #data_male_n = data[male_idx.ravel(),:]\n",
    "    #data_female_n = data[female_idx.ravel(),:]\n",
    "    \n",
    "    #generate arrays of sex labels for males and females\n",
    "    #sex_male = sex[male_idx.ravel(),:]\n",
    "    #sex_female = sex[female_idx.ravel(),:]\n",
    "    \n",
    "    #concatenate male and female data together\n",
    "    #idx_2n = np.concatenate([idx_male_n,idx_female_n])\n",
    "    #data_2n = np.concatenate([data_male_n,data_female_n])\n",
    "    #sex_2n = np.concatenate([sex_male,sex_female])\n",
    "    \n",
    "    #save subject indices\n",
    "    #subj_idx[idx,:] = idx_422.ravel()\n",
    "    \n",
    "    #split data into train and test subsets\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(data, sex, test_size = 0.2, stratify = sex, shuffle=True)\n",
    "    \n",
    "    #split data into training and testing sets using pre-determined indices (generated in HCP_HE_sexclf_traintestsplit notebook)\n",
    "    #this was done this way to make sure all atlases have the exact same train-test split \n",
    "    \n",
    "    test=test_indices[idx,:]\n",
    "\n",
    "    #get indices for training and testing subsets\n",
    "    train_idx=np.isin(num,test,invert=True)\n",
    "    test_idx=np.isin(num,test)\n",
    "\n",
    "    #partition data and sex labels into training and testing subsets\n",
    "    x_train=data[train_idx.ravel(),:]\n",
    "    x_test=data[test_idx.ravel(),:]\n",
    "    y_train=sex[train_idx.ravel(),:]\n",
    "    y_test=sex[test_idx.ravel(),:]\n",
    "    \n",
    "    \n",
    "    #set all the hyperparameters you want to tune using nested CV\n",
    "    #course search\n",
    "    #param_grid = {'clf__kernel': ['linear'], 'clf__C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]}\n",
    "    #fine search\n",
    "    param_grid = {'clf__kernel': ['linear'], 'clf__C': [x*0.001 + 0.001 for x in range(500)]}\n",
    "\n",
    "    #set number of iterations through nested CV loop\n",
    "    iterations=100\n",
    "    \n",
    "    #set up pipeline for analysis so that data transformation takes place within each CV fold\n",
    "    cv_steps = [('scaler', StandardScaler()), ('clf', SVC(max_iter=100000))]\n",
    "    cv_pipeline = Pipeline(cv_steps)\n",
    "\n",
    "    #create array to store nested CV scores\n",
    "    nested_scores = np.zeros(iterations)\n",
    "\n",
    "    best_params = ['']*iterations\n",
    "\n",
    "    #set up nested CV pipeline\n",
    "    for iter in range(iterations):\n",
    "    \n",
    "        print(\"Nested CV - Loop %d\" % (iter + 1))\n",
    "\n",
    "        #set parameters for inner and outer loops for CV\n",
    "        #using 5 fold but can do more/less folded if desired\n",
    "        inner_cv = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "        outer_cv = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "    \n",
    "    \n",
    "        #print specific hyperparameter being tuned\n",
    "        #print(\"Tuning hyperparameters for %s\" % score)\n",
    "\n",
    "        #define classifier with pipeline and grid-search CV for inner loop\n",
    "        clf = GridSearchCV(cv_pipeline, param_grid = param_grid, cv = inner_cv, \n",
    "                           scoring='roc_auc', n_jobs = -1, iid = False, refit = True, verbose=0)\n",
    "\n",
    "        #fit classifier\n",
    "        clf.fit(x_train, y_train.ravel())\n",
    "\n",
    "        #save parameters corresponding to the best score\n",
    "        best_params[iter] = clf.best_params_\n",
    "        #print(\"Best Parameters = %s\" % clf.best_params_)\n",
    "        #print()\n",
    "\n",
    "        #print detailed classification report\n",
    "        #print(\"Detailed classification report:\")\n",
    "        #print(\"The model is trained on the full development set.\")\n",
    "        #print(\"The scores are computed on the full validation set.\")\n",
    "        #print()\n",
    "        #y_true, y_pred = y_val, clf.predict(x_val)\n",
    "        #print(classification_report(y_true, y_pred))\n",
    "\n",
    "        #call cross_val_score for outer loop\n",
    "        nested_score = cross_val_score(clf, X = x_train, y = y_train.ravel(), cv = outer_cv, \n",
    "                                       scoring = 'roc_auc', verbose = 0)\n",
    "        nested_scores[iter] = nested_score.mean()\n",
    "\n",
    "   #save best_params in txt file\n",
    "    with open('best_params.txt', 'w') as f:\n",
    "        for listitem in best_params:\n",
    "            f.write('%s\\n' % listitem)\n",
    "        \n",
    "    #extract best C parameter from txt file saved above from all iterations and compute mean \n",
    "    cv_params = pd.read_csv('best_params.txt', sep='\\s+', header=None)\n",
    "    cv_params = cv_params[1].str.replace(',','')\n",
    "    best_c = np.zeros(iterations)\n",
    "    for i in range(len(best_c)):\n",
    "        best_c[i] = eval(cv_params[i])\n",
    "    optimised_c[idx] = np.mean(best_c)\n",
    "    #print(\"Optimised C = %1.4f\" %(optimised[idx]))\n",
    "    \n",
    "    #normalize all training data and fit trasnformation to test data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train_t = scaler.transform(x_train)\n",
    "    x_test_t = scaler.transform(x_test)\n",
    "    \n",
    "    #generate SVC model based on optimised parameters \n",
    "    #uses optimised_c hyperparameter optained by averaging hyperparameters over grid search iterations\n",
    "    model = SVC(C = optimised_c[idx], kernel='linear', probability=True);\n",
    "    model.fit(x_train_t, y_train.ravel());\n",
    "    \n",
    "    #generate prediction probailities for test samples\n",
    "    pred = model.predict_proba(x_test_t);\n",
    "    predictions[idx,:] = pred[:,1]\n",
    "    \n",
    "    #save y_test so ROC curves can be generated later\n",
    "    #test_y[idx,:] = y_test.ravel()\n",
    "    \n",
    "    #determine model accuracy and store it in score variable\n",
    "    accuracy[idx] = model.score(x_test_t,y_test.ravel())\n",
    "    #print(\"Accuracy = %1.4f\" %(accuracy[idx]))\n",
    "    \n",
    "    #determine model AUC and store it in AUC variable\n",
    "    auc[idx] = metrics.roc_auc_score(y_test.ravel(), pred[:,1]) \n",
    "    #print(\"AUC = %1.4f\" %(auc[idx]))\n",
    "    \n",
    "    #save feature importances\n",
    "    feat_imp[idx] = model.coef_[0]\n",
    "    \n",
    "    #save at the end of each permutation so if something does go wrong, it's all saved \n",
    "    #just gets overwritten after each permutation\n",
    "    np.savetxt('optc.txt', optimised_c, delimiter=',')\n",
    "    np.savetxt('acc.txt', accuracy, delimiter=',')\n",
    "    np.savetxt('pred.txt', predictions, delimiter=',')\n",
    "    np.savetxt('auc.txt', auc, delimiter=',')\n",
    "    np.savetxt('featimp.txt', feat_imp, delimiter=',')\n",
    "\n",
    "    \n",
    "np.savetxt('optc.txt', optimised_c, delimiter=',')\n",
    "np.savetxt('acc.txt', accuracy, delimiter=',')\n",
    "np.savetxt('pred.txt', predictions, delimiter=',')\n",
    "np.savetxt('auc.txt', auc, delimiter=',')\n",
    "np.savetxt('featimp.txt', feat_imp, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
